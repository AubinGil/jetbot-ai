# JetBot AI Environment Configuration
# Copy this file to .env and customize for your setup

# ==================== ROS2 Configuration ====================
export ROS_DOMAIN_ID=37
export RMW_IMPLEMENTATION=rmw_fastrtps_cpp

# ==================== Local Services ====================
# Local Ollama (running on Jetson)
export OLLAMA_HOST=http://localhost:11434

# ==================== Remote Services (Optional) ====================
# Remote Cosmos Server (e.g., RTX GPU PC running vLLM)
# export COSMOS_HOST=http://192.168.2.16:8000
# export COSMOS_MODEL=nvidia/Cosmos-Reason1-7B

# Remote Ollama Server (optional backup)
# export OLLAMA_REMOTE_HOST=http://192.168.2.29:11434
# export OLLAMA_REMOTE_MODEL=minicpm-v:8b

# Remote GGUF Backend (optional)
# export GGUF_SERVER=http://192.168.2.16:8001

# ==================== Language Settings ====================
# Language: 'en' for English, 'fr' for French
export CONVERSATION_LANGUAGE=en

# Narration language for autonomous navigation
export NARRATION_LANGUAGE=en

# ==================== Hardware Device Paths ====================
# Camera device (USB camera)
export CAMERA_DEV=/dev/video0

# Motor controller (USB serial)
export MOTOR_DEV=/dev/ttyACM0

# LiDAR (RPLidar)
export LIDAR_DEV=/dev/ttyUSB0

# ==================== Model Paths ====================
# Whisper ASR model (tiny.en, base.en, small.en)
export WHISPER_MODEL=tiny.en

# Piper TTS model (offline speech)
export PIPER_MODEL=${HOME}/en_US-lessac-medium.onnx

# YOLO ONNX models
export YOLO_DETECT_MODEL=${HOME}/jetbot-ai/models/onnx/yolo11n.onnx
export YOLO_POSE_MODEL=${HOME}/jetbot-ai/models/onnx/yolo11n-pose.onnx

# ==================== Navigation Parameters ====================
# Movement speeds
export LIN_SPEED=0.20  # Linear speed (m/s)
export ANG_SPEED=0.45  # Angular speed (rad/s)

# Safety distances (meters)
export SAFETY_DISTANCE=0.15
export WARNING_DISTANCE=0.25

# ==================== Optional Features ====================
# Enable TTS narration during autonomous navigation
export TTS=0  # Set to 1 to enable

# Enable voice mode controller
export MODE_CONTROL_ENABLED=1

# Enable adaptive transformer (predictive smoothing)
export ADAPTIVE_TRANSFORMER_ENABLED=false

# Enable wall following
export WALL_FOLLOW_ENABLED=false

# ==================== API Keys (Keep Private!) ====================
# Magpie TTS Token (get from https://build.nvidia.com)
# export MAGPIE_TOKEN=your-token-here

# OpenAI API Key (optional, for GPT models)
# export OPENAI_API_KEY=your-key-here

# ==================== Advanced Settings ====================
# SLAM resolution (meters per pixel)
# export SLAM_RESOLUTION=0.05

# Context memory size (conversation history)
# export CONTEXT_MEMORY_SIZE=5

# Verbose logging
# export ROS_LOG_LEVEL=debug
